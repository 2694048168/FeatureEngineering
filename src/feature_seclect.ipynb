{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征选择\n",
    "# 1、相关性\n",
    "# 2、互信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9996222851612185, 0.017498096813275913)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1、相关性\n",
    "\n",
    "# 简述：相关性，容易看到特征之间的线性关系，可用一条直线拟合\n",
    "\n",
    "# 皮尔逊相关系数（Pearson correlation coefficient）\n",
    "# 计算两个序列之间的相关性，从 -1 到 1， -1代表负相关， 1代表正相关， 0代表不相关\n",
    "\n",
    "# scipy.stats.pearsonr()，给定两个数据序列 ，会返回相关系数值和 p 值所组成的元组\n",
    "# 皮尔逊相关系数（皮尔逊 r 值）测量两个序列的线性关系，取值在 -1 到 1 之间，-1代表负相关、1代表正相关、0代表不相关\n",
    "\n",
    "# r 值计算：\n",
    "# r_pb = sum( ( x - m_x )( y - m_y ) ) / sqrt( sum ( ( x - m_x ) ** 2 ( y - m_y ) ** 2 ) )\n",
    "# 上式中 m_x 是向量 x 的均值，m_y 是向量 y 的均值\n",
    "# p 值是该序列产生于一个不相关系统的概率，p 值越高，越不能信任这个相关系数\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "pearsonr([1,2,3], [1,2,3.1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/pearsonr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一 、 第二 、 第三 具有高相关性\n",
    "# 说明两个特征传递着相似或者一样的信息，可以选择舍弃其中一个特征\n",
    "# 最后一个，相关性低，两个特征都保留\n",
    "\n",
    "# 基于相关性的特征选择方法的一个最大的缺点就是\n",
    "#    只检测出线性关系（可用一条直线拟合的关系）\n",
    "# 对于非线性关系就无法解决，比如二次抛物线\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于非线性关系，互信息能够解决这个问题\n",
    "\n",
    "# 2.互信息\n",
    "\n",
    "# 在进行特征选择时，不该把焦点放在数据关系的类型（线性关系）上\n",
    "#    而是要考虑在已经给定另一个特征的情况下一个特征可以提供多少信息量（类似计算线性代数职工的条件概率）\n",
    "\n",
    "# 互信息会通过计算两个特征所共有的信息，把上述推理工程形式化表达出来\n",
    "#    与相关性不同，它依赖的不是数据序列，而是数据的分布\n",
    "\n",
    "# 香农 (Claude Shannon）的 信息熵 ( Entropy H(X) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/ectropy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以使用信息熵来计算进行度量 一个特征使另一个特征的不确定性减少的程度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/formation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/onrformation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 互信息的一个较好的性质在于，跟相关性不同，它并不只关注线性关系\n",
    "\n",
    "# 需要计算每一对特征之间的归一互信息量\n",
    "# 对于具有较高互信息量的特征对，把其中一个特征扔掉\n",
    "# 在进行回归的时候，可以把互信息量非常低的特征扔掉\n",
    "\n",
    "\n",
    "# 对于较小的特征集合这种方式的效果或许还可以\n",
    "# 但是，在某种程度上，这个过程会非常缓慢，计算量会以平方级别增长，因为计算的是每对特征之间的互信息量\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
