{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单数字的奇特技巧\n",
    "# fancy tricks with simple numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数字数据已经是数学模型容易消化的格式\n",
    "# 数字特征工程技术是基础\n",
    "# 当原始数据被转换为数字特征时，它们可以被应用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数值数据的第一个健全检查是 —— 大小是否重要\n",
    "#       只需要知道它是正面的还是负面的？\n",
    "#       或者只需要知道一个非常粗粒度的大小？\n",
    "#      这一明智的检查对于自动累积数尤其重要，比如统计，每天访问网站的次数，餐馆所获得的评论数量等等\n",
    "\n",
    "# 考虑特征的规模\n",
    "#        最大值和最小值是什么？\n",
    "#        它们跨越几个数量级吗？\n",
    "#        输入特性平滑的模型对输入的尺度敏感\n",
    "\n",
    "# 考虑数值特征的分布也是很重要的\n",
    "#       分布总结了承担特定价值的可能性\n",
    "#      输入特征的分布对某些模型比其他模型更重要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标量  向量  向量空间\n",
    "\n",
    "# 向量可以被可视化为空间中的一个点\n",
    "# 在数据世界中, 抽象向量及其特征维度具有实际意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/figure2-2.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 二值化\n",
    "import pandas as pd\n",
    "listen_count = pd.read_csv('millionsong/train_triplets.txt.zip', header=None, delimiter='\\t')\n",
    "# The table contains user-song-count triplets. Only non-zero counts are\n",
    "# included. Hence to binarize the count, we just need to set the entire\n",
    "# count column to 1.\n",
    "listen_count[2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于许多模型来说，跨越数个数量级的原始计数是有问题的\n",
    "# 在线性模型中，相同的线性系数必须对计数的所有可能值工作\n",
    "# 数据向量的一个元素中的大计数将超过所有其他元素中的相似性，这可能会丢弃整个相似性度量。\n",
    "\n",
    "# 一种解决方案是通过量化计数来包含标量\n",
    "# 换句话说，将计数分组到容器中，并且去掉实际的计数值\n",
    "# 量化将连续数映射成离散数\n",
    "# 可以把离散化的数字看作是代表强度度量的容器的有序的序列\n",
    "\n",
    "# 为了量化数据，必须决定每一个箱子应该有多宽\n",
    "# 解决方案分为固定宽度或自适应两种类型\n",
    "\n",
    "\n",
    "# 分位数装箱\n",
    "# 固定宽度装箱很容易计算，但是如果计数有很大的差距, 那么将会有许多空的垃圾箱没有数据\n",
    "# 该问题可以通过基于数据分布的垃圾箱自适应定位来解决，这可以使用分发的分位数来完成\n",
    "\n",
    "# 分位数是将数据划分为相等部分的值\n",
    "# 例如, 中位数将数据分成一半;一半的数据是较小的, 一半大于中位数\n",
    "# 分位数把数据分成几个部分, 十分位数把数据划分成十份\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数变换是处理具有重尾分布的正数的有力工具\n",
    "# （重尾分布在尾部范围内的概率比高斯分布的概率大）\n",
    "# 它将分布在高端的长尾压缩成较短的尾部，并将低端扩展成较长的头部\n",
    "\n",
    "# 对数和指数是互逆运算\n",
    "# 对于数值的量化有所帮助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 功率变换：对数变换的推广\n",
    "\n",
    "# 对数变换是一个称为功率变换的变换族的特殊例子\n",
    "# 在统计方面，这些是方差稳定的变换\n",
    "# 为了理解为什么方差稳定是好的，考虑泊松分布\n",
    "# 这是一个方差等于它的平均值的重尾分布\n",
    "# 因此，它的质量中心越大，其方差越大，尾部越重\n",
    "# 功率变换改变变量的分布，使得方差不再依赖于平均值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 概率图是一种直观地比较数据分布与理论分布的简单方法\n",
    "# 这本质上是观察到散点图的与理论分位数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征缩放或归一化\n",
    "# 某些特征的值有界的，如纬度或经度。其他数值特征 (如数量) 可能会在无界的情况下增加\n",
    "# 如果模型对输入特征的数值范围敏感, 则特征缩放可能会有所帮助\n",
    "# 顾名思义, 特征缩放会更改特征值的数值范围，有时人们也称它为特征规范化\n",
    "\n",
    "# 功能缩放通常分别针对单个特征进行\n",
    "# 有几种常见的缩放操作, 每个类型都产生不同的特征值分布\n",
    "\n",
    "\n",
    "# Min-max缩放\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/figure2-15.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化（方差缩放）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/figure2-16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要中心化稀疏数据\n",
    "\n",
    "# 最小最大缩放和标准化都从原始特征值中减去一个数量\n",
    "# 对于最小最大缩放, 移动量是当前特征的所有值中最小的\n",
    "# 对于标准化, 移动的量是平均值\n",
    "# 如果移动量不是零, 则这两种转换可以将稀疏特征（大部分值为零）的向量转换为一个稠密的向量\n",
    "# 这反过来会给分类器带来巨大的计算负担, 取决于它是如何实现的\n",
    "# 请谨慎对稀疏特征执行最小最大缩放和标准化操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ℓ2 Normalization\n",
    "# L2 范数\n",
    "\n",
    "# 这项技术通过所谓的 L2 范数 (也称为欧几里德范数) 正常化 (划分) 原始特征值\n",
    "# L2范数度量向量在坐标空间中的长度\n",
    "# L2 范数将求特征的各数据点的平方和, 然后取平方根\n",
    "# L2 规范化后, 该特征列具有范数 1 ，它也可以称为 L2 缩放\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/figure2-17.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据空间与特征空间  这是两个概念，注意区别\n",
    "\n",
    "\n",
    "# 交互特征\n",
    "# 简单的成对交互特征是两个特征的积\n",
    "# 一个简单的线性模型使用单个输入特征线性组合 x1，x2，... xn 来预测结果 y\n",
    "# 一个简单的扩展线性模型的方法是包含输入特征对的组合\n",
    "# 这能够捕获特征之间的相互影响，因此它们被称为交互特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征选择\n",
    "# 特征选择技术会删除非有用的特征，以降低最终模型的复杂性\n",
    "# 最终目标是快速计算的简约模型，预测准确性降低很小或不会降低\n",
    "# 为了得到这样的模型，一些特征选择技术需要训练多个候选模型\n",
    "\n",
    "# 换句话说，特征选择并不是减少训练时间，实际上有些技巧增加了整体训练时间，但是减少了模型评分时间\n",
    "\n",
    "# 粗略地说，特征选择技术分为三类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Filtering（过滤）\n",
    "#     预处理可以删除那些不太可能对模型有用的特征\n",
    "\n",
    "# 例如，可以计算每个特征与响应变量之间的相关或相互信息，并筛除相关信息或相互信息低于阈值的特征\n",
    "\n",
    "# 2 Wrapper methods（包装方法）\n",
    "#      这些技术是昂贵的，但它们允许尝试特征子集，这意味着不会意外删除自身无法提供信息但在组合使用时非常有用的特征\n",
    "#     包装方法将模型视为提供特征子集质量分数的黑盒子\n",
    "\n",
    "# 3 Embedded methods（嵌入式方法）\n",
    "#      嵌入式方法执行特征选择作为模型训练过程的一部分\n",
    "\n",
    "# 例如，决策树固有地执行特征选择，因为它在每个训练步骤选择一个要在其上进行树分裂的特征\n",
    "\n",
    "\n",
    "# 总结\n",
    "# 本章讨论了许多常见的数字特征工程技术\n",
    "#      量化，缩放（又称规范化），对数变换（一种功率变换），交互特征以及处理大量交互特征所需的特征选择技术的简要总结\n",
    "#  在统计机器学习中，所有数据最终归结为数字特征\n",
    "#  因此，所有道路最终都会指向某种数字特征工程技术\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
