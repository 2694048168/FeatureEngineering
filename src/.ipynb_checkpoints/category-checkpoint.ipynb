{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对类别特征进行编码\n",
    "\n",
    "# 分类变量的类别通常不是数字\n",
    "# 例如，眼睛的颜色可以是“黑色”，“蓝色”，“棕色”等\n",
    "\n",
    "# 因此，需要使用编码方法将这些非数字类别变为数字\n",
    "#  简单地将一个整数（比如 1 到 k ）分配给 k 个可能的类别中的每一个都是诱人的\n",
    "#  但是，由此产生的价值观可以互相授权，这在类别中不应该被允许\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  One-hot 编码\n",
    "\n",
    "# 将类别特征进行表示一个最好的办法就是使用一组比特位来表达\n",
    "# 每一位代表一个可能的类别\n",
    "# 如果该变量不能一次成为多个类别，那么该组中只有一位可以是 1 \n",
    "\n",
    "# 这被称为独热编码，它在 Scikit Learn 中实现\n",
    "# [sklearn.preprocessing.OneHotEncoder]\n",
    "# (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "# 每个位都是一个特征， 因此是一个绝对的具有 k 个可能类别的变量被编码为长度为 k 的特征向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy编码\n",
    "\n",
    "# 独热编码的问题是它允许 k 个自由度，其中变量本身只需要 k-1\n",
    "\n",
    "#  虚拟编码通过仅使用表示中的 k-1 个特征来消除额外的自由度\n",
    "\n",
    "# 虚拟编码 和 独热编码都是在 Pandas 中以 的形式实现的\n",
    "# [pandas.get_dummies]\n",
    "# (http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "\n",
    "# 使用虚拟编码进行建模的结果比单编码更易解释\n",
    "# 这很容易在简单的线性回归问题中看到\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect编码\n",
    "\n",
    "# 分类变量编码的另一种变体称为 Effect 编码\n",
    "#  Effect 编码与虚拟编码非常相似，区别在于参考类别现在由所有 -1 的向量表示\n",
    "\n",
    "# Effect编码与虚拟编码非常相似，但是在线性回归中更容易被拟合\n",
    "# 查看[what is effect coding?]\n",
    "# (https://stats.idre.ucla.edu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理大量的类别特征\n",
    "# 面临的挑战是如何找到一个能够提高内存效率的优秀特征表示，并生成训练速度快的准确模型\n",
    "\n",
    "# 互联网上的自动数据收集可以生成大量的分类变量\n",
    "# 这在诸如定向广告和欺诈检测等应用中很常见\n",
    "\n",
    "# 对于这种类别特征处理的方案有：\n",
    "#     1. 对编码不做任何事情。 使用便宜的训练简单模型。 在许多机器上将独热编码引入线性模型（逻辑回归或线性支持向量机）\n",
    "#     2. 压缩编码，有两种方式\n",
    "#         a. 对特征进行哈希--在线性回归中特别常见\n",
    "#         b. bin-counting--在线性回归中与树模型都常见\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征哈希\n",
    "\n",
    "# 散列函数是一个确定性函数，它映射一个潜在的无界整数到有限整数范围 [1，m]\n",
    "# 由于输入域可能大于输出范围，多个数字可能会映射到相同的输出, 这被称为 a 碰撞\n",
    "\n",
    "#  统一的散列函数可确保大致相同数量的数字被映射到每个 m 箱\n",
    "\n",
    "# 散列函数可以为任何可以用数字表示的对象构造（对于可以存储在计算机上的任何数据都是如此）：数字，字符串，复杂的结构等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self](./../image/figure5-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin-counting\n",
    "\n",
    "# Bin-counting 是机器学习中常见的重新发现之一\n",
    "#    是一种特征工程技术，而不是一种建模或优化方法，所以没有关于该主题的研究论文\n",
    "\n",
    "# bin-counting 的想法非常简单：不是使用分类变量作为特征，而是使用条件概率的目标在该价值下\n",
    "#  换句话说，而不是编码的身份分类值，计算该值和该值之间的关联统计量我们希望预测的目标\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总结\n",
    "\n",
    "# Plain one-hot encoding\n",
    "# 空间使用：O(n)\n",
    "# 时间复杂度：O(nk)\n",
    "# 优点:\n",
    "#    * 容易实现\n",
    "#    * 更高的精度\n",
    "#    * 在线学习特别容易扩展\n",
    "# 缺点\n",
    "#    * 计算不足\n",
    "#    * 如果类别增加则不能够使用\n",
    "#    * 对线性模型以外的任何其他方法都不可行\n",
    "#    * 对于大数据集需要分布式训练\n",
    "\n",
    "# Feature hashing\n",
    "# 空间使用：O(n)\n",
    "# 时间复杂度：O(nm)\n",
    "# 优点:\n",
    "#    * 容易实现\n",
    "#    * 容易训练\n",
    "#    * 容易扩展到新类别\n",
    "#    * 容易处理稀有类别\n",
    "#    * 在线学习容易扩展\n",
    "# 缺点\n",
    "#    * 只能够使用线性或核模型\n",
    "#    * 哈希编码很难解释\n",
    "#    * 精度有争议\n",
    "\n",
    "# Bin-counting\n",
    "# 空间使用：O(n+k)\n",
    "# 时间复杂度：O(n)\n",
    "# 优点:\n",
    "#    * 训练快\n",
    "#    * 能够使用树模型\n",
    "#    * 容易扩展到新列类别\n",
    "#    * 容易处理稀有类别\n",
    "#    * 可解释\n",
    "# 缺点\n",
    "#    * 需要利用历史信息\n",
    "#    * 对于在线学习有困难\n",
    "#    * 会有数据泄露\n",
    "\n",
    "\n",
    "# 正如我们所看到的，没有任何方法是完美的\n",
    "#  选择使用哪一个取决于所需的型号\n",
    "# 线性模型比较便宜，因此可以进行训练处理非压缩表示，例如独热编码\n",
    "# 基于树的模型，另一方面，需要反复搜索右侧分割的所有特征，并且是因此限于小型表示，如箱计数\n",
    "# 功能哈希处于在这两个极端之间，但是由此产生的精确度有不同的报道\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
